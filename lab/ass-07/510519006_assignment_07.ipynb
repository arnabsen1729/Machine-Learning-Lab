{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnGqSrPCgdrk"
      },
      "source": [
        "# Assignment 7\n",
        "- Name: Arnab Sen\n",
        "- Enrolment Number: 510519006\n",
        "- Dept: CST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsp7pcJOgdrm"
      },
      "source": [
        "## Task 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBn_CSGShStx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, GRU, Bidirectional, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from keras.utils.layer_utils import count_params\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7D_MuU7gdrn"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  \n",
        "tf.config.set_visible_devices([], 'GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVOCwiYdgdro"
      },
      "outputs": [],
      "source": [
        "AMAZON_REVIEW_PATH = \"./../ML_DRIVE/Assign_7/Amazon Review/Reviews.csv\"\n",
        "GLOVE_FILE_PATH = \"./../ML_DRIVE/Assign_7/glove.6B/glove.6B.100d.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9K_OJpcgdro",
        "outputId": "9c33e5f2-82e5-4afd-d1bd-5f2276f786c0"
      },
      "outputs": [],
      "source": [
        "review_df = pd.read_csv(AMAZON_REVIEW_PATH)\n",
        "review_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpCzehw7gdro",
        "outputId": "d5557c1c-f88b-41b8-e584-5c579807a411"
      },
      "outputs": [],
      "source": [
        "review_df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxIl687ugdrp",
        "outputId": "175d42d8-a95e-49cc-8532-83939f3eb20f"
      },
      "outputs": [],
      "source": [
        "columns_to_keep = ['Score', 'Summary', 'Text']\n",
        "\n",
        "review_df = review_df[columns_to_keep]\n",
        "\n",
        "review_df.iloc[0:1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmTCaOOQgdrp",
        "outputId": "73428490-aab3-42b0-d589-c72d124e4e4d"
      },
      "outputs": [],
      "source": [
        "review_df['full_review'] = review_df['Summary'] + ' ' + review_df['Text']\n",
        "review_df = review_df.drop(['Summary', 'Text'], axis=1)\n",
        "\n",
        "review_df.iloc[0:1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0X-0HifhI7R"
      },
      "source": [
        "## Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc1XTs8Cgdrp",
        "outputId": "9a5c2f89-42e1-43de-a3e4-8f84545fabef"
      },
      "outputs": [],
      "source": [
        "# 1 = true, 0 = false\n",
        "review_df['review score'] = np.where(review_df.Score > 3, 1, 0)\n",
        "review_df = review_df.drop(['Score'], axis=1)\n",
        "review_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ38_6K-gdrp"
      },
      "outputs": [],
      "source": [
        "# taking 2000 samples for test and validation dataset\n",
        "test_df = review_df.sample(2000, random_state=100)\n",
        "val_df = review_df.sample(2000, random_state=100)\n",
        "review_df = review_df.drop(test_df.index.tolist() + val_df.index.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICKCvy7Ygdrq",
        "outputId": "83e8a4ca-6022-4c67-dcf0-ecf215ffce1f"
      },
      "outputs": [],
      "source": [
        "review_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWL1EQ7egdrq",
        "outputId": "46e6850c-6680-4c70-ca71-ebc36f1d67b2"
      },
      "outputs": [],
      "source": [
        "true_df = review_df[review_df['review score'] == 1]\n",
        "false_df = review_df[review_df['review score'] == 0]\n",
        "\n",
        "true_df = true_df.sample(5000, random_state=100)\n",
        "false_df = false_df.sample(5000, random_state=100)\n",
        "\n",
        "train_df = pd.concat([true_df, false_df]).sort_index()\n",
        "\n",
        "train_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV8quca4gdrq"
      },
      "outputs": [],
      "source": [
        "# using TextVectorization to index the vocabulary\n",
        "vectorizer = TextVectorization(output_sequence_length=100)\n",
        "vectorizer.adapt(train_df['full_review'].to_list())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfHoYLQLgdrq",
        "outputId": "a68a2418-55ae-4806-ddcf-06cfbb1df9fd"
      },
      "outputs": [],
      "source": [
        "# Note the first two are default \"empty\" and \"unknown\" vocabulary word\n",
        "vectorizer.get_vocabulary()[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7e2_r8Hgdrq"
      },
      "outputs": [],
      "source": [
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))\n",
        "\n",
        "# Now we have the vocabulary encoding of all the words\n",
        "# in the training dataset in the vectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWqGabsEgdrq",
        "outputId": "0dda2301-b0eb-40d1-e884-82cfe6bd9f24"
      },
      "outputs": [],
      "source": [
        "embedding_index = {}\n",
        "\n",
        "with open(GLOVE_FILE_PATH) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, dtype=float, sep=\" \")\n",
        "        embedding_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embedding_index)} word vectors.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRpJGqgggdrq",
        "outputId": "d4bcb59a-1a18-45c5-cf7c-dcc92130d675"
      },
      "outputs": [],
      "source": [
        "# now converting it into an embedding layer for using it directly on model\n",
        "\n",
        "num_tokens = len(voc) + 2  # +2 for \"empty\" and \"unknown\"\n",
        "embedding_dim = 100  # cause using glove 100 model\n",
        "hits = 0  # number of words in vocabulary that are also in the glove map\n",
        "misses = 0  # number of words in vocabulary that are not in the glove map\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "\n",
        "print(f\"Converted {hits} word, {misses} misses\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGSH77Argdrr"
      },
      "outputs": [],
      "source": [
        "glove_embedding = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVfRjuTAgdrr"
      },
      "outputs": [],
      "source": [
        "x_train = vectorizer(\n",
        "    np.array(\n",
        "        [[s] for s in train_df['full_review'].tolist()]\n",
        "    )\n",
        ").numpy()\n",
        "\n",
        "x_val = vectorizer(\n",
        "    np.array(\n",
        "        [[s] for s in val_df['full_review'].tolist()]\n",
        "    )\n",
        ").numpy()\n",
        "\n",
        "x_test = vectorizer(\n",
        "    np.array(\n",
        "        [[s] for s in test_df['full_review'].tolist()]\n",
        "    )\n",
        ").numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLigoj0vgdrr"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(train_df['review score'].tolist())\n",
        "y_val = to_categorical(val_df['review score'].tolist())\n",
        "y_test = to_categorical(test_df['review score'].tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMFHU3Ylgdrr"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [12, 5]\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    x_val,\n",
        "    y_val,\n",
        "    rnn_type: str,\n",
        "    num_rnn_layers: int,\n",
        "    rnn_layer_unit: int,\n",
        "    embedding_layer_type: str,\n",
        "    bidirectional: bool,\n",
        "    rnn_drop_rate: float,\n",
        "    drop_rate: float,\n",
        "    num_epochs: int = 30,\n",
        "    give_model=False\n",
        "):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(None, ), dtype=\"int64\"))\n",
        "\n",
        "    if embedding_layer_type == 'glove':\n",
        "        model.add(glove_embedding)\n",
        "    elif embedding_layer_type == 'trainable_embedding':\n",
        "        model.add(Embedding(num_tokens, embedding_dim))\n",
        "    elif embedding_layer_type == 'one_hot':\n",
        "        model.add(\n",
        "            Embedding(np.ones((num_tokens, num_tokens)), trainable=False)\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        raise Exception('Error: undefined embedding_layer_type')\n",
        "\n",
        "    # return_sequences=True does not reduce the Dimension Count of Output\n",
        "    for _ in range(0, num_rnn_layers-1):\n",
        "        if rnn_drop_rate != 0:\n",
        "            model.add(Dropout(rnn_drop_rate))\n",
        "\n",
        "        if bidirectional:\n",
        "            if rnn_type == 'lstm':\n",
        "                model.add(Bidirectional(\n",
        "                    LSTM(rnn_layer_unit, activation='relu',\n",
        "                         return_sequences=True)\n",
        "                ))\n",
        "            elif rnn_type == 'gru':\n",
        "                model.add(Bidirectional(\n",
        "                    GRU(rnn_layer_unit, activation='relu',\n",
        "                        return_sequences=True)\n",
        "                ))\n",
        "            else:\n",
        "                raise Exception('Error: undefined rnn_type')\n",
        "        else:\n",
        "            if rnn_type == 'lstm':\n",
        "                model.add(\n",
        "                    LSTM(rnn_layer_unit, activation='relu',\n",
        "                         return_sequences=True)\n",
        "                )\n",
        "            elif rnn_type == 'gru':\n",
        "                model.add(\n",
        "                    GRU(rnn_layer_unit, activation='relu',\n",
        "                        return_sequences=True)\n",
        "                )\n",
        "            else:\n",
        "                raise Exception('Error: undefined rnn_type')\n",
        "\n",
        "    if rnn_drop_rate != 0:\n",
        "        model.add(Dropout(rnn_drop_rate))\n",
        "\n",
        "    if bidirectional:\n",
        "        if rnn_type == 'lstm':\n",
        "            model.add(Bidirectional(\n",
        "                LSTM(rnn_layer_unit, activation='relu')\n",
        "            ))\n",
        "        elif rnn_type == 'gru':\n",
        "            model.add(Bidirectional(\n",
        "                GRU(rnn_layer_unit, activation='relu')\n",
        "            ))\n",
        "        else:\n",
        "            raise Exception('Error: undefined rnn_type')\n",
        "    else:\n",
        "        if rnn_type == 'lstm':\n",
        "            model.add(LSTM(rnn_layer_unit, activation='relu'))\n",
        "        elif rnn_type == 'gru':\n",
        "            model.add(GRU(rnn_layer_unit, activation='relu'))\n",
        "        else:\n",
        "            raise Exception('Error: undefined rnn_type')\n",
        "\n",
        "    if drop_rate != 0:\n",
        "        model.add(Dropout(drop_rate))\n",
        "\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(2, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    callback = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=(x_val, y_val),\n",
        "        callbacks=callback,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    if give_model:\n",
        "        return model\n",
        "        \n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    start_time = time.time()\n",
        "    val_loss, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "    infer_time = time.time() - start_time\n",
        "\n",
        "    num_param = count_params(model.trainable_weights)\n",
        "\n",
        "    plt.plot(\n",
        "        history.history['loss'],\n",
        "        label=f\"{num_rnn_layers} layers;{rnn_type};{rnn_layer_unit} units;{embedding_layer_type} embed;bidirec {bidirectional};drop {drop_rate};rnn_drop {rnn_drop_rate}\"\n",
        "    )\n",
        "\n",
        "    return num_param, val_loss, val_acc, train_time, infer_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a0wvRhbgdrr"
      },
      "outputs": [],
      "source": [
        "result_df = pd.DataFrame(columns=[\n",
        "    'RNN Type',\n",
        "    'RNN Layer',\n",
        "    'RNN Size',\n",
        "    'Embedding Layer',\n",
        "    'Bidirectional',\n",
        "    'RNN Dropout Rate',\n",
        "    'Dropout Rate',\n",
        "    'Num Params',\n",
        "    'Val Loss',\n",
        "    'Val Accuracy',\n",
        "    'Train Time (s)',\n",
        "    'Infer Time (s)'\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbLoMGSjgdrr"
      },
      "source": [
        "## Task 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6FBFoufgdrr",
        "outputId": "a61ee0fe-a8ac-4c7f-8399-77c9cad16976"
      },
      "outputs": [],
      "source": [
        "rnn_types = ['lstm', 'gru']\n",
        "num_rnn_layers = 1\n",
        "rnn_layer_unit = 64\n",
        "embedding_layer_type = 'glove'\n",
        "bidirectional = False\n",
        "rnn_drop_rate = 0\n",
        "drop_rate = 0\n",
        "\n",
        "\n",
        "for rnn_type in rnn_types:\n",
        "    num_param, val_loss, val_acc, train_time, infer_time = train_model(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        x_val,\n",
        "        y_val,\n",
        "        rnn_type=rnn_type,\n",
        "        num_rnn_layers=num_rnn_layers,\n",
        "        rnn_layer_unit=rnn_layer_unit,\n",
        "        embedding_layer_type=embedding_layer_type,\n",
        "        bidirectional=bidirectional,\n",
        "        rnn_drop_rate=rnn_drop_rate,\n",
        "        drop_rate=drop_rate\n",
        "    )\n",
        "\n",
        "    print(f\"{num_rnn_layers} layers;{rnn_type};{rnn_layer_unit} units;{embedding_layer_type} embed;bidirec {bidirectional};drop {drop_rate};rnn_drop {rnn_drop_rate} => {num_param} Params;val_loss={val_loss};val_acc={round(val_acc,2)};train_time={round(train_time,2)}s;infer_time={round(infer_time,2)}s\")\n",
        "\n",
        "    result_df.loc[len(result_df.index)] = [\n",
        "        rnn_type,\n",
        "        num_rnn_layers,\n",
        "        rnn_layer_unit,\n",
        "        embedding_layer_type,\n",
        "        bidirectional,\n",
        "        rnn_drop_rate,\n",
        "        drop_rate,\n",
        "        num_param,\n",
        "        val_loss,\n",
        "        val_acc,\n",
        "        train_time,\n",
        "        infer_time\n",
        "    ]\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.title(f'Training Loss vs epoch')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlGLfX3Qgdrs",
        "outputId": "62d9c0c3-e8d7-45b8-c983-82920f31e8dc"
      },
      "outputs": [],
      "source": [
        "result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGP6dmC4gdrs",
        "outputId": "1e5b2058-5ff6-4213-a174-729e59d7c45e"
      },
      "outputs": [],
      "source": [
        "best_rnn_type = result_df.sort_values(\n",
        "    by=['Val Accuracy', 'Val Loss'],\n",
        "    ascending=[False, True]\n",
        ")['RNN Type'].iloc[0]\n",
        "\n",
        "best_rnn_type\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYUrB9KUgdrs"
      },
      "source": [
        "## Task 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Du72DSjogdrs",
        "outputId": "f7af5f01-5a71-476c-b26e-d2eb708eaaa7"
      },
      "outputs": [],
      "source": [
        "num_rnn_layers = 1\n",
        "rnn_layer_units = [32, 128]\n",
        "embedding_layer_type = 'glove'\n",
        "bidirectional = False\n",
        "rnn_drop_rate = 0\n",
        "drop_rate = 0\n",
        "\n",
        "\n",
        "for rnn_layer_unit in rnn_layer_units:\n",
        "    num_param, val_loss, val_acc, train_time, infer_time = train_model(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        x_val,\n",
        "        y_val,\n",
        "        rnn_type=best_rnn_type,\n",
        "        num_rnn_layers=num_rnn_layers,\n",
        "        rnn_layer_unit=rnn_layer_unit,\n",
        "        embedding_layer_type=embedding_layer_type,\n",
        "        bidirectional=bidirectional,\n",
        "        rnn_drop_rate=rnn_drop_rate,\n",
        "        drop_rate=drop_rate\n",
        "    )\n",
        "\n",
        "    print(f\"{num_rnn_layers} layers;{best_rnn_type};{rnn_layer_unit} units;{embedding_layer_type} embed;bidirec {bidirectional};drop {drop_rate};rnn_drop {rnn_drop_rate} => {num_param} Params;val_loss={val_loss};val_acc={round(val_acc,2)};train_time={round(train_time,2)}s;infer_time={round(infer_time,2)}s\")\n",
        "\n",
        "    result_df.loc[len(result_df.index)] = [\n",
        "        best_rnn_type,\n",
        "        num_rnn_layers,\n",
        "        rnn_layer_unit,\n",
        "        embedding_layer_type,\n",
        "        bidirectional,\n",
        "        rnn_drop_rate,\n",
        "        drop_rate,\n",
        "        num_param,\n",
        "        val_loss,\n",
        "        val_acc,\n",
        "        train_time,\n",
        "        infer_time\n",
        "    ]\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.title(f'Training Loss vs epoch')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJN4yrVvgdrs",
        "outputId": "b0142d68-f009-43ef-c0b0-2eff8adf1295"
      },
      "outputs": [],
      "source": [
        "result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-vCxON7gdrs",
        "outputId": "f1876907-c4c8-45f1-b321-822d51bb9cc1"
      },
      "outputs": [],
      "source": [
        "best_rnn_layer_unit = result_df.sort_values(\n",
        "    by=['Val Accuracy', 'Val Loss'],\n",
        "    ascending=[False, True]\n",
        ")['RNN Size'].iloc[0]\n",
        "\n",
        "best_rnn_layer_unit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wofKEtJugdrs"
      },
      "source": [
        "## Task 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydAkrGHkgdrs",
        "outputId": "0c8c4ce2-3501-4ff8-a6d3-08f7234c3e66"
      },
      "outputs": [],
      "source": [
        "num_rnn_layers = [2, 3, 4]\n",
        "embedding_layer_type = 'glove'\n",
        "bidirectional = False\n",
        "rnn_drop_rate = 0\n",
        "drop_rate = 0\n",
        "\n",
        "for num_rnn_layer in num_rnn_layers:\n",
        "    num_param, val_loss, val_acc, train_time, infer_time = train_model(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        x_val,\n",
        "        y_val,\n",
        "        rnn_type=best_rnn_type,\n",
        "        num_rnn_layers=num_rnn_layer,\n",
        "        rnn_layer_unit=best_rnn_layer_unit,\n",
        "        embedding_layer_type=embedding_layer_type,\n",
        "        bidirectional=bidirectional,\n",
        "        rnn_drop_rate=rnn_drop_rate,\n",
        "        drop_rate=drop_rate\n",
        "    )\n",
        "\n",
        "    print(f\"{num_rnn_layer} layers;{best_rnn_type};{best_rnn_layer_unit} units;{embedding_layer_type} embed;bidirec {bidirectional};drop {drop_rate};rnn_drop {rnn_drop_rate} => {num_param} Params;val_loss={val_loss};val_acc={round(val_acc,2)};train_time={round(train_time,2)}s;infer_time={round(infer_time,2)}s\")\n",
        "\n",
        "    result_df.loc[len(result_df.index)] = [\n",
        "        best_rnn_type,\n",
        "        num_rnn_layer,\n",
        "        best_rnn_layer_unit,\n",
        "        embedding_layer_type,\n",
        "        bidirectional,\n",
        "        rnn_drop_rate,\n",
        "        drop_rate,\n",
        "        num_param,\n",
        "        val_loss,\n",
        "        val_acc,\n",
        "        train_time,\n",
        "        infer_time\n",
        "    ]\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.title(f'Training Loss vs epoch')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSQkQ8Pfgdrs",
        "outputId": "6c934f89-cfea-4723-f1e3-60fab40ee131"
      },
      "outputs": [],
      "source": [
        "result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znzjdZ03gdrs",
        "outputId": "f128a55e-10e8-4944-e99b-44300f541b4f"
      },
      "outputs": [],
      "source": [
        "best_num_rnn_layer = result_df.sort_values(\n",
        "    by=['Val Accuracy', 'Val Loss'],\n",
        "    ascending=[False, True]\n",
        ")['RNN Layer'].iloc[0]\n",
        "\n",
        "best_num_rnn_layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHi921-ngdrs"
      },
      "source": [
        "## Task 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEucStAAgdrs",
        "outputId": "88cd807e-7cf4-4fe7-f7d6-202f71578c06"
      },
      "outputs": [],
      "source": [
        "embedding_layer_type = 'glove'\n",
        "bidirectional = True\n",
        "rnn_drop_rate = 0\n",
        "drop_rate = 0\n",
        "\n",
        "num_param, val_loss, val_acc, train_time, infer_time = train_model(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    x_val,\n",
        "    y_val,\n",
        "    rnn_type=best_rnn_type,\n",
        "    num_rnn_layers=best_num_rnn_layer,\n",
        "    rnn_layer_unit=best_rnn_layer_unit,\n",
        "    embedding_layer_type=embedding_layer_type,\n",
        "    bidirectional=bidirectional,\n",
        "    rnn_drop_rate=rnn_drop_rate,\n",
        "    drop_rate=drop_rate\n",
        ")\n",
        "\n",
        "print(f\"{best_num_rnn_layer} layers;{best_rnn_type};{best_rnn_layer_unit} units;{embedding_layer_type} embed;bidirec {bidirectional};drop {drop_rate};rnn_drop {rnn_drop_rate} => {num_param} Params;val_loss={val_loss};val_acc={round(val_acc,2)};train_time={round(train_time,2)}s;infer_time={round(infer_time,2)}s\")\n",
        "\n",
        "result_df.loc[len(result_df.index)] = [\n",
        "    best_rnn_type,\n",
        "    best_num_rnn_layer,\n",
        "    best_rnn_layer_unit,\n",
        "    embedding_layer_type,\n",
        "    bidirectional,\n",
        "    rnn_drop_rate,\n",
        "    drop_rate,\n",
        "    num_param,\n",
        "    val_loss,\n",
        "    val_acc,\n",
        "    train_time,\n",
        "    infer_time\n",
        "]\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.title(f'Training Loss vs epoch')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_lD2uxYgdrt",
        "outputId": "db11c362-3875-4e29-8c71-b64bd4b59db3"
      },
      "outputs": [],
      "source": [
        "result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhN-SFBVgdrt",
        "outputId": "2ce3c9a7-2a69-4402-afb1-2a4c9f7167b4"
      },
      "outputs": [],
      "source": [
        "best_bidirectional = result_df.sort_values(\n",
        "    by=['Val Accuracy', 'Val Loss'],\n",
        "    ascending=[False, True]\n",
        ")['Bidirectional'].iloc[0]\n",
        "\n",
        "best_bidirectional\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDYJqeOtgdrt"
      },
      "source": [
        "## Task 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg_zTKPHgdrt",
        "outputId": "95ae9201-5f74-4246-cba8-38ab1bfcd228"
      },
      "outputs": [],
      "source": [
        "embedding_layer_type = 'glove'\n",
        "rnn_drop_rates = [0, 0.2, 0.2]\n",
        "drop_rates = [0.1, 0, 0.1]\n",
        "\n",
        "for rnn_drop_rate, drop_rate in zip(rnn_drop_rates, drop_rates):\n",
        "    num_param, val_loss, val_acc, train_time, infer_time = train_model(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        x_val,\n",
        "        y_val,\n",
        "        rnn_type=best_rnn_type,\n",
        "        num_rnn_layers=best_num_rnn_layer,\n",
        "        rnn_layer_unit=best_rnn_layer_unit,\n",
        "        embedding_layer_type=embedding_layer_type,\n",
        "        bidirectional=best_bidirectional,\n",
        "        rnn_drop_rate=rnn_drop_rate,\n",
        "        drop_rate=drop_rate\n",
        "    )\n",
        "\n",
        "    print(f\"{best_num_rnn_layer} layers;{best_rnn_type};{best_rnn_layer_unit} units;{embedding_layer_type} embed;bidirec {best_bidirectional};drop {drop_rate};rnn_drop {rnn_drop_rate} => {num_param} Params;val_loss={val_loss};val_acc={round(val_acc,2)};train_time={round(train_time,2)}s;infer_time={round(infer_time,2)}s\")\n",
        "\n",
        "    result_df.loc[len(result_df.index)] = [\n",
        "        best_rnn_type,\n",
        "        best_num_rnn_layer,\n",
        "        best_rnn_layer_unit,\n",
        "        embedding_layer_type,\n",
        "        best_bidirectional,\n",
        "        rnn_drop_rate,\n",
        "        drop_rate,\n",
        "        num_param,\n",
        "        val_loss,\n",
        "        val_acc,\n",
        "        train_time,\n",
        "        infer_time\n",
        "    ]\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.title(f'Training Loss vs epoch')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYxI-B35gdrt",
        "outputId": "eed43d17-6bac-4406-9892-af1ef0aaaffd"
      },
      "outputs": [],
      "source": [
        "result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0QZkCBegdrt",
        "outputId": "21cdf7ad-2d4a-460c-8531-0211054bc909"
      },
      "outputs": [],
      "source": [
        "best_rnn_drop_rate = result_df.sort_values(\n",
        "    by=['Val Accuracy', 'Val Loss'],\n",
        "    ascending=[False, True]\n",
        ")['RNN Dropout Rate'].iloc[0]\n",
        "\n",
        "best_rnn_drop_rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDmJeNPNgdrt",
        "outputId": "e4c3f847-e7bc-4e43-a4cd-6ad84f665357"
      },
      "outputs": [],
      "source": [
        "best_drop_rate = result_df.sort_values(\n",
        "    by=['Val Accuracy', 'Val Loss'],\n",
        "    ascending=[False, True]\n",
        ")['Dropout Rate'].iloc[0]\n",
        "\n",
        "best_drop_rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeyzwcFBgdrt"
      },
      "source": [
        "## Task 8, 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBrw8VjOgdrt",
        "outputId": "405036fb-0b42-4660-e247-ba09d82edc3c"
      },
      "outputs": [],
      "source": [
        "# one_hot skipped because of RAM limitation\n",
        "# unable to create 40k x 40k matrix\n",
        "embedding_layer_types = ['trainable_embedding']\n",
        "\n",
        "for embedding_layer_type in embedding_layer_types:\n",
        "    num_param, val_loss, val_acc, train_time, infer_time = train_model(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        x_val,\n",
        "        y_val,\n",
        "        rnn_type=best_rnn_type,\n",
        "        num_rnn_layers=best_num_rnn_layer,\n",
        "        rnn_layer_unit=best_rnn_layer_unit,\n",
        "        embedding_layer_type=embedding_layer_type,\n",
        "        bidirectional=best_bidirectional,\n",
        "        rnn_drop_rate=best_rnn_drop_rate,\n",
        "        drop_rate=best_drop_rate\n",
        "    )\n",
        "\n",
        "    print(f\"{best_num_rnn_layer} layers;{best_rnn_type};{best_rnn_layer_unit} units;{embedding_layer_type} embed;bidirec {best_bidirectional};drop {best_drop_rate};rnn_drop {best_rnn_drop_rate} => {num_param} Params;val_loss={val_loss};val_acc={round(val_acc,2)};train_time={round(train_time,2)}s;infer_time={round(infer_time,2)}s\")\n",
        "\n",
        "    result_df.loc[len(result_df.index)] = [\n",
        "        best_rnn_type,\n",
        "        best_num_rnn_layer,\n",
        "        best_rnn_layer_unit,\n",
        "        embedding_layer_type,\n",
        "        best_bidirectional,\n",
        "        best_rnn_drop_rate,\n",
        "        best_drop_rate,\n",
        "        num_param,\n",
        "        val_loss,\n",
        "        val_acc,\n",
        "        train_time,\n",
        "        infer_time\n",
        "    ]\n",
        "\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.title(f'Training Loss vs epoch')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-WE0aCogdrt",
        "outputId": "9b996850-5295-4983-96f7-dc7d4923e133"
      },
      "outputs": [],
      "source": [
        "result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB_eNZjRgdrt",
        "outputId": "4520f748-0210-413e-9df0-c63b8431f9ef"
      },
      "outputs": [],
      "source": [
        "best_embedding_layer_type = result_df.sort_values(\n",
        "    by=['Val Accuracy', 'Val Loss'],\n",
        "    ascending=[False, True]\n",
        ")['Embedding Layer'].iloc[0]\n",
        "\n",
        "best_embedding_layer_type\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOWScJFggdrt"
      },
      "source": [
        "## Task 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noonXEsLgdrt",
        "outputId": "5543f905-a066-47f7-9677-78622f262150"
      },
      "outputs": [],
      "source": [
        "result_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSE8-EHugdrt"
      },
      "source": [
        "## Task 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--JAR7u_gdrt",
        "outputId": "08aa106f-ffd4-4b21-81f2-5e7bd96d73f4"
      },
      "outputs": [],
      "source": [
        "print(f\"best_rnn_type = {best_rnn_type}\")\n",
        "print(f\"best_num_rnn_layer = {best_num_rnn_layer}\")\n",
        "print(f\"best_rnn_layer_unit = {best_rnn_layer_unit}\")\n",
        "print(f\"best_embedding_layer_type = {best_embedding_layer_type}\")\n",
        "print(f\"best_bidirectional = {best_bidirectional}\")\n",
        "print(f\"best_rnn_drop_rate = {best_rnn_drop_rate}\")\n",
        "print(f\"best_drop_rate = {best_drop_rate}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i63pW3Vagdru"
      },
      "outputs": [],
      "source": [
        "model = train_model(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        x_val,\n",
        "        y_val,\n",
        "        rnn_type=best_rnn_type,\n",
        "        num_rnn_layers=best_num_rnn_layer,\n",
        "        rnn_layer_unit=best_rnn_layer_unit,\n",
        "        embedding_layer_type=best_embedding_layer_type,\n",
        "        bidirectional=best_bidirectional,\n",
        "        rnn_drop_rate=best_rnn_drop_rate,\n",
        "        drop_rate=best_drop_rate,\n",
        "        give_model=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REtO830mgdru",
        "outputId": "973426bb-f03a-4944-c00d-b0a1413c6b0a"
      },
      "outputs": [],
      "source": [
        "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f\"val_loss = {val_loss}\")\n",
        "print(f\"val_acc  = {val_acc }\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEOTEh14gdru",
        "outputId": "64993e4b-cf44-46c9-e855-ba1fc1126a78"
      },
      "outputs": [],
      "source": [
        "model.save('best_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mn70dl0qgdru",
        "outputId": "914b4af7-aebc-437c-ea6f-50d9d6e317df"
      },
      "outputs": [],
      "source": [
        "model = load_model('best_model')\n",
        "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f\"val_loss = {val_loss}\")\n",
        "print(f\"val_acc  = {val_acc }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewOrNHb7gdru"
      },
      "source": [
        "## Task 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJd4s5-Egdru"
      },
      "outputs": [],
      "source": [
        "HINDI_REVIEW_TRAIN_PATH = \"./../ML_DRIVE/Assign_7/Hindi Movie/train.csv\"\n",
        "HINDI_REVIEW_VAL_PATH = \"./../ML_DRIVE/Assign_7/Hindi Movie/valid.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad2v-1Epgdru",
        "outputId": "dd1bfa30-5037-4638-9f8c-f579753dbb17"
      },
      "outputs": [],
      "source": [
        "hindi_train_df = pd.read_csv(HINDI_REVIEW_TRAIN_PATH)\n",
        "hindi_val_df = pd.read_csv(HINDI_REVIEW_VAL_PATH)\n",
        "\n",
        "hindi_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL9J75ZSgdru"
      },
      "outputs": [],
      "source": [
        "hindi_train_df['experience'] = np.where(\n",
        "    hindi_train_df['experience'] >= 1, 1, 0\n",
        ")\n",
        "\n",
        "hindi_val_df['experience'] = np.where(\n",
        "    hindi_val_df['experience'] >= 1, 1, 0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGT94ytJgdru",
        "outputId": "6f17ae68-aba4-4e39-f10b-5fac6b97a573"
      },
      "outputs": [],
      "source": [
        "vectorizer = TextVectorization(output_sequence_length=100)\n",
        "vectorizer.adapt(hindi_train_df['text'].to_list())\n",
        "vectorizer.get_vocabulary()[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1HEZmBygdru"
      },
      "outputs": [],
      "source": [
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))\n",
        "num_tokens = len(voc) + 2  # +2 for \"empty\" and \"unknown\"\n",
        "embedding_dim = 100  # cause using glove 100 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxV0Tvuqgdru"
      },
      "outputs": [],
      "source": [
        "hindi_x_train =  vectorizer(\n",
        "    np.array(\n",
        "        [[s] for s in hindi_train_df['text'].tolist()]\n",
        "    )\n",
        ").numpy()\n",
        "\n",
        "hindi_x_val =  vectorizer(\n",
        "    np.array(\n",
        "        [[s] for s in hindi_val_df['text'].tolist()]\n",
        "    )\n",
        ").numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk5VUjC5gdru"
      },
      "outputs": [],
      "source": [
        "hindi_y_train = to_categorical(hindi_train_df['experience'].tolist())\n",
        "hindi_y_val = to_categorical(hindi_val_df['experience'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m-4LDoPgdru",
        "outputId": "4b55e5cc-28a5-4fa2-9495-532af2d59c7b"
      },
      "outputs": [],
      "source": [
        "hindi_model = Sequential()\n",
        "hindi_model.add(Input(shape=(None, ), dtype=\"int64\"))\n",
        "hindi_model.add(Embedding(num_tokens, embedding_dim))\n",
        "\n",
        "for layer in model.layers[1:]:\n",
        "    hindi_model.add(layer)\n",
        "    hindi_model.layers[-1].trainable = False\n",
        "\n",
        "hindi_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qjTTvDvgdru",
        "outputId": "5ebebf71-695a-4526-c13c-b13ca88b3d81"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "callback = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    hindi_x_train,\n",
        "    hindi_y_train,\n",
        "    epochs=100,\n",
        "    validation_data=(hindi_x_val, hindi_y_val),\n",
        "    callbacks=callback,\n",
        "    verbose=2\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7 (main, Oct 26 2022, 14:14:16) [Clang 14.0.0 (clang-1400.0.29.102)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "5f90c9c72ce04906de37d4c67574a63377e4fd7d3965d8d2cd20954f66a8e417"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
